# ğŸš€ Triton Inference Server - MLOps Model Deployment

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-required-blue.svg)](https://www.docker.com/)
[![Triton](https://img.shields.io/badge/NVIDIA-Triton-green.svg)](https://github.com/triton-inference-server/server)

A production-ready MLOps project demonstrating how to deploy PyTorch and Python-based machine learning models using **NVIDIA Triton Inference Server**. This repository showcases model serving, ensemble pipelines, preprocessing/postprocessing, and client integration.

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [Models](#-models)
- [Project Structure](#-project-structure)
- [Setup Guide](#-setup-guide)
- [Usage](#-usage)
- [Documentation](#-documentation)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

---

## âœ¨ Features

- **ğŸ¯ Multi-Model Deployment**: Deploy PyTorch, TorchScript, and Python backend models
- **ğŸ”— Ensemble Pipelines**: Chain models for end-to-end inference (preprocessing â†’ inference â†’ postprocessing)
- **âš¡ Dynamic Batching**: Automatic request batching for improved throughput
- **ğŸ³ Docker Support**: Containerized deployment with Docker Compose
- **ğŸ“Š Multiple Backends**: PyTorch, Python, and Ensemble model support
- **ğŸ§ª Complete Examples**: Jupyter notebooks for training and client testing
- **ğŸ“ Comprehensive Logging**: Detailed logging and monitoring guide
- **ğŸ”„ Model Versioning**: Support for multiple model versions
- **ğŸŒ REST API**: HTTP/REST interface for easy integration
- **ğŸ“¦ Production Ready**: Includes error handling, validation, and best practices

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â”‚ (HTTP/REST) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   NVIDIA Triton Inference Server    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   PyTorch    â”‚  â”‚   Python    â”‚ â”‚
â”‚  â”‚   Backend    â”‚  â”‚   Backend   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                 â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚     Ensemble Pipelines        â”‚ â”‚
â”‚  â”‚  â€¢ Image Classification       â”‚ â”‚
â”‚  â”‚  â€¢ Sentiment Analysis         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Pipeline Example (ResNet Ensemble):

```
Input Image (numpy array)
    â”‚
    â–¼
[Preprocessor] â†’ Resize, Normalize, Transform
    â”‚
    â–¼
[ResNet50 Model] â†’ 1000 ImageNet logits
    â”‚
    â–¼
[Postprocessor] â†’ Class label + Confidence
    â”‚
    â–¼
Output: {"class": "bucket", "confidence": 0.85}
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Docker**: Version 20.10+
- **Docker Compose**: Version 1.29+
- **Python**: 3.8+ (for training and client)
- **NVIDIA GPU** (recommended) with CUDA support

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/yourusername/model_deployment.git
cd model_deployment
```

### 2ï¸âƒ£ Download Models

Models are not included in the repository (too large for Git). Download them using:

```bash
# Option 1: Download pretrained models
./scripts/download_models.sh

# Option 2: Train simple models locally
python scripts/train_simple_models.py
```

**Note**: ResNet50 (~99MB) and BERT classifier (~256MB) will be downloaded from PyTorch Hub and Hugging Face.

### 3ï¸âƒ£ Start Triton Server

```bash
cd configs
docker-compose up -d
```

### 4ï¸âƒ£ Verify Deployment

```bash
# Check server health
curl http://localhost:8000/v2/health/ready

# List loaded models
curl -X POST http://localhost:8000/v2/repository/index
```

### 5ï¸âƒ£ Run Example Notebook

```bash
pip install jupyter tritonclient[http] numpy pillow
jupyter notebook notebooks/client.ipynb
```

---

## ğŸ¯ Models

| Model Name | Type | Purpose | Input | Output | Size |
|------------|------|---------|-------|--------|------|
| `linear_regression_model` | PyTorch | Simple regression | (batch, 1) | (batch, 1) | 4 KB |
| `resnet_model` | PyTorch | Image classification | (batch, 3, 224, 224) | (batch, 1000) | 99 MB |
| `resnet_ensemble` | Ensemble | End-to-end image pipeline | RGB image | label + confidence | - |
| `torch_classifier` | PyTorch | BERT text classification | tokenized text | (batch, 2) | 256 MB |
| `text_ensemble` | Ensemble | End-to-end sentiment | raw text | sentiment + confidence | - |
| `sentiment` | Python | 5-star sentiment rating | raw text | label + score | - |

**Ensemble Models** (recommended for production):
- **`resnet_ensemble`**: Preprocessing â†’ ResNet50 â†’ Postprocessing
- **`text_ensemble`**: Tokenization â†’ BERT â†’ Label Mapping

See [`model_repository/README.md`](model_repository/README.md) for detailed model specifications.

---

## ğŸ“ Project Structure

```
model_deployment/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ docker-compose.yaml       # Docker Compose configuration
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ TRITON_LOGGING_GUIDE.md   # Comprehensive logging guide
â”‚   â”œâ”€â”€ MODEL_SETUP.md            # Model download and setup
â”‚   â”œâ”€â”€ API_GUIDE.md              # API usage examples
â”‚   â””â”€â”€ TROUBLESHOOTING.md        # Common issues and fixes
â”œâ”€â”€ model_repository/
â”‚   â”œâ”€â”€ README.md                 # Model documentation
â”‚   â”œâ”€â”€ linear_regression_model/  # Simple linear regression
â”‚   â”œâ”€â”€ resnet_model/             # ResNet50 PyTorch model
â”‚   â”œâ”€â”€ resnet_preprocessor/      # Image preprocessing
â”‚   â”œâ”€â”€ resnet_postprocessor/     # Classification postprocessing
â”‚   â”œâ”€â”€ resnet_ensemble/          # Complete image pipeline
â”‚   â”œâ”€â”€ torch_classifier/         # BERT text classifier
â”‚   â”œâ”€â”€ text_preprocessor/        # Text tokenization
â”‚   â”œâ”€â”€ text_postprocessor/       # Sentiment label mapping
â”‚   â”œâ”€â”€ text_ensemble/            # Complete text pipeline
â”‚   â””â”€â”€ sentiment/                # 5-star sentiment model
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ README.md                 # Notebook documentation
â”‚   â”œâ”€â”€ train.ipynb               # Model training examples
â”‚   â””â”€â”€ client.ipynb              # Triton client examples
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_models.sh        # Download pretrained models
â”‚   â””â”€â”€ train_simple_models.py    # Train simple demo models
â”œâ”€â”€ src/
â”‚   â””â”€â”€ test.py                   # Client test scripts
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ .gitkeep                  # Unit tests (to be added)
â”œâ”€â”€ .dockerignore                 # Docker build exclusions
â”œâ”€â”€ .gitignore                    # Git exclusions
â”œâ”€â”€ Dockerfile                    # Triton server image
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ LICENSE                       # MIT License
â””â”€â”€ README.md                     # This file
```

---

## ğŸ› ï¸ Setup Guide

### Local Development Setup

```bash
# 1. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Download models
./scripts/download_models.sh

# 4. Start Triton server
cd configs && docker-compose up -d

# 5. Run tests
python src/test.py
```

### Docker Configuration

The `configs/docker-compose.yaml` includes:
- **Shared Memory**: 1GB for Python backend models
- **GPU Support**: NVIDIA runtime for GPU acceleration
- **Port Mappings**:
  - `8000`: HTTP REST API
  - `8001`: gRPC API
  - `8002`: Metrics endpoint
- **Volume Mount**: Links local `model_repository/` to container

**Important**: Ensure models are downloaded before starting Docker.

---

## ğŸ“– Usage

### HTTP REST API

#### Check Server Health

```bash
curl http://localhost:8000/v2/health/live
curl http://localhost:8000/v2/health/ready
```

#### List Models

```bash
curl -X POST http://localhost:8000/v2/repository/index
```

#### Inference Example (Linear Regression)

```bash
curl -X POST http://localhost:8000/v2/models/linear_regression_model/infer \
  -H "Content-Type: application/json" \
  -d '{
    "inputs": [{
      "name": "input__0",
      "shape": [1, 1],
      "datatype": "FP32",
      "data": [5.0]
    }]
  }'
```

#### Inference Example (ResNet Ensemble)

```python
import tritonclient.http as httpclient
from PIL import Image
import numpy as np

# Load and prepare image
image = Image.open("cat.jpg").convert("RGB")
image_array = np.array(image)

# Create Triton client
client = httpclient.InferenceServerClient(url="localhost:8000")

# Prepare input
input_data = httpclient.InferInput("input_image", image_array.shape, "UINT8")
input_data.set_data_from_numpy(image_array)

# Run inference
result = client.infer("resnet_ensemble", inputs=[input_data])

# Get outputs
label = result.as_numpy("class_label")[0].decode()
confidence = result.as_numpy("confidence")[0]

print(f"Prediction: {label} ({confidence:.2%})")
```

See [`docs/API_GUIDE.md`](docs/API_GUIDE.md) for more examples.

---

## ğŸ“š Documentation

- **[Triton Logging Guide](docs/TRITON_LOGGING_GUIDE.md)**: Complete guide to viewing and debugging logs
- **[Model Setup](docs/MODEL_SETUP.md)**: Detailed model download and configuration
- **[API Guide](docs/API_GUIDE.md)**: REST API usage and code examples
- **[Troubleshooting](docs/TROUBLESHOOTING.md)**: Common issues and solutions
- **[Model Repository](model_repository/README.md)**: Model specifications
- **[Notebooks](notebooks/README.md)**: Jupyter notebook documentation

---

## ğŸ› Troubleshooting

### Common Issues

**1. Models Not Loading**
```bash
# Check model files exist
ls -lh model_repository/*/1/model.*

# Check Triton logs
docker logs triton-server

# Verify config files
cat model_repository/resnet_model/config.pbtxt
```

**2. Shared Memory Error (Python Backend)**
```
Error: Shared memory region creation failed
```
**Solution**: Increase `shm_size` in `docker-compose.yaml` to `'2gb'`

**3. Connection Refused**
```bash
# Check if Triton is running
docker ps | grep triton

# Wait for models to load (can take 30-60 seconds)
docker logs -f triton-server
```

See [`docs/TROUBLESHOOTING.md`](docs/TROUBLESHOOTING.md) for more solutions.

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

See [`CONTRIBUTING.md`](CONTRIBUTING.md) for guidelines.

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **NVIDIA Triton Inference Server**: https://github.com/triton-inference-server/server
- **PyTorch**: https://pytorch.org/
- **Hugging Face Transformers**: https://huggingface.co/transformers/

---

## ğŸ“¬ Contact

- **Issues**: [GitHub Issues](https://github.com/yourusername/model_deployment/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/model_deployment/discussions)

---

## ğŸŒŸ Star History

If you find this project useful, please consider giving it a â­!

---

**Built with â¤ï¸ for the MLOps community**